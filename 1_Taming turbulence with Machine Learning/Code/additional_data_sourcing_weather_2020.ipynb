{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e81c55c-f186-47cb-b464-97a088129c19",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Data Sourcing\n",
    "\n",
    "- Based on Phase 3 requirements: Pull the data for recent years; Provide a clean dataset for Flights and/or Weather for Years 2020-2023.\n",
    "- Save as parquet file, with same structure as raw datasets\n",
    "\n",
    "**TO DO:**\n",
    "- Weather data is available at https://www.ncei.noaa.gov/data/local-climatological-data/archive/ up to 2024. \n",
    "- Flights data is available at: https://www.transtats.bts.gov/homepage.asp \n",
    "\n",
    "- Data dictionary for flights: https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ\n",
    "- Data dictionary for weather: https://www.ncei.noaa.gov/pub/data/cdo/documentation/LCD_documentation.pdf\n",
    "\n",
    "**Flights data**\n",
    "- This is a subset of the passenger flight's on-time performance data taken from the TranStats data collection available from the U.S. Department of Transportation (DOT) https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJLinks The flight dataset was downloaded from the US Department of Transportation and contains flight information from 2015 to 2021.\n",
    "\n",
    "**Weather data**\n",
    "- The weather dataset was downloaded from the National Oceanic and Atmospheric Administration repositoryLinks to an external site. and contains weather information from 2015 to 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee13f961-d9a7-43f6-9731-ce0261ffac8b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Setup cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52673ca5-0af9-40b6-8ba1-71ce00d4ae99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "blob_container = \"261storagecontainer\"  \n",
    "storage_account = \"261storage\" \n",
    "secret_scope = \"261_team_6_1_spring24_scope\"  \n",
    "secret_key = \"team_6_1_key\"  \n",
    "team_blob_url = f\"wasbs://{blob_container}@{storage_account}.blob.core.windows.net\" \n",
    "\n",
    "\n",
    "# blob storage is mounted here.\n",
    "mids261_mount_path = \"/mnt/mids-w261\"\n",
    "\n",
    "# SAS Token: Grant the team limited access to Azure Storage resources\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net\",\n",
    "    dbutils.secrets.get(scope=secret_scope, key=secret_key),\n",
    ")\n",
    "\n",
    "# see what's in the blob storage root folder\n",
    "# display(dbutils.fs.ls(f\"{team_blob_url}\"))\n",
    "\n",
    "# mount\n",
    "data_BASE_DIR = \"dbfs:/mnt/mids-w261/\"\n",
    "# display(dbutils.fs.ls(f\"{data_BASE_DIR}\"))\n",
    "\n",
    "# uploading files to the DBFS via File -> Upload data to DBFS\n",
    "my_file_system = \"dbfs:/FileStore/shared_uploads/julianagc@berkeley.edu/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "235c76c4-4129-480f-a7be-fa70c6907931",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72219f50-0dcf-456c-bb21-c3cc4b7821ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#standard\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F #cleaning: split, col, when, lit, concat_ws,regexp_replace, regexp_extract\n",
    "import seaborn as sns\n",
    "\n",
    "#imputing\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "#normalization and feature extraction\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler,PCA\n",
    "\n",
    "# to download files from url\n",
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f3f5b77-10e7-426f-bd94-59660efdc15e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Load raw data (weather and flights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12d65c1f-0548-4382-b276-b9636b6606d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display(dbutils.fs.ls(f\"{data_BASE_DIR}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15a9e3da-c120-4920-84ae-65d43170e1a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Weather data\n",
    "df_weather = spark.read.parquet(f\"dbfs:/mnt/mids-w261/datasets_final_project_2022/parquet_weather_data/\")\n",
    "# display(df_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "398767e7-cee9-4e8d-8c7a-ec3290eaa572",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Flights data\n",
    "# df_flights = spark.read.parquet(f\"dbfs:/mnt/mids-w261/datasets_final_project_2022/parquet_airlines_data/\")\n",
    "# display(df_flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e86fc0e-cc6d-4dd4-9fc2-20a17f1ba7cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38d57ad3-855e-4ac7-8409-e85cc2a859c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "defe169d-52dd-4474-9b0c-d5be7da19443",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "weather_url = [\"https://www.ncei.noaa.gov/data/local-climatological-data/archive/2020.tar.gz\",\"https://www.ncei.noaa.gov/data/local-climatological-data/archive/2022.tar.gz\",\"https://www.ncei.noaa.gov/data/local-climatological-data/archive/2022.tar.gz\",\"https://www.ncei.noaa.gov/data/local-climatological-data/archive/2023.tar.gz\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4e2e097-5439-4d18-9417-7c91db0d5796",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a folder for downloaded files\n",
    "dbutils.fs.mkdirs(f\"{team_blob_url}/weather_data_2020\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e38b934e-bf6e-42f6-b30c-67e55e01ac56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# see team blob contents\n",
    "display(dbutils.fs.ls(f\"{team_blob_url}/weather_data_2020\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c510cf1e-04de-4d11-a3c9-c5444f2f76c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2020 folder\n",
    "weather_20_dir = f\"{team_blob_url}/weather_data_2020\"\n",
    "\n",
    "# Download the tar.gz file\n",
    "url = \"https://www.ncei.noaa.gov/data/local-climatological-data/archive/2020.tar.gz\"\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "# Extract the tar.gz file\n",
    "tar_file = tarfile.open(fileobj=BytesIO(response.content), mode=\"r:gz\")\n",
    "\n",
    "# Loop through the extracted files and save to blob storage\n",
    "for member in tar_file.getmembers():\n",
    "    if member.isfile():\n",
    "        file_name = member.name.split(\"/\")[-1]\n",
    "        file_bytes = tar_file.extractfile(member).read()\n",
    "        file_contents = file_bytes.decode()  # Convert bytes to string\n",
    "\n",
    "        # Write the file to blob storage\n",
    "        dbutils.fs.put(os.path.join(weather_20_dir, file_name), file_contents, overwrite=True)\n",
    "\n",
    "# Close the tar file\n",
    "tar_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8488e79a-b924-4858-930a-dc90d56a5d65",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Save all files as a single parquet file per year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45a17f27-d5e5-45b0-8643-b922e7ad3cb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the path to the CSV files\n",
    "csv_path = \"wasbs://261storagecontainer@261storage.blob.core.windows.net/weather_data_2020/*.csv\"\n",
    "\n",
    "# Read the CSV files into a DataFrame\n",
    "weather_20_df = spark.read.csv(csv_path, header=True, inferSchema=True)\n",
    "\n",
    "# Add a column with the file name\n",
    "weather_20_df = weather_20_df.withColumn(\"source_file\", F.input_file_name())\n",
    "\n",
    "# Write the DataFrame as a Parquet file\n",
    "weather_20_df.write.mode(\"overwrite\").parquet(\"wasbs://261storagecontainer@261storage.blob.core.windows.net/weather_data_2020/weather_20_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f608082-2d15-4925-b668-a6e58334936e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#load checkpointed 2020 weather\n",
    "weather_20_df = spark.read.parquet(\"wasbs://261storagecontainer@261storage.blob.core.windows.net/weather_data_2020/weather_20_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "989487ae-e375-44ec-b0e7-d5724dc52bc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "weather_20_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d0c74fe-4114-48fc-9bd7-a6aa6cb7ed3a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Number of files per year\n",
    "|Year|Number of files (stations)|\n",
    "|---|---|\n",
    "|2020|13562|\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3944613696792873,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "additional_data_sourcing_weather_2020",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
