{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "059a094a-1c1c-45ca-bc22-025bbd4448d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# US Holidays and Special Events\n",
    "\n",
    "- New Year's Day\n",
    "- MLK\n",
    "- Super Bowl\n",
    "- Presidents Day\n",
    "- Memorial Day\n",
    "- Independence Day\n",
    "- Labor Day\n",
    "- Columbus Day\n",
    "- Veterans Day\n",
    "- Thanksgiving\n",
    "- Christmas\n",
    "- New Year's Eve\n",
    "\n",
    "Sources: \n",
    "- https://www.usa.gov/holidays\n",
    "- https://www.timeanddate.com/holidays/us/2015\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fd610ec-830b-4a6c-8f25-34dcd98792cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c76cc4c-bd2a-4229-9783-67b3e50460d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "blob_container = \"261storagecontainer\"  \n",
    "storage_account = \"261storage\" \n",
    "secret_scope = \"261_team_6_1_spring24_scope\"  \n",
    "secret_key = \"team_6_1_key\"  \n",
    "team_blob_url = f\"wasbs://{blob_container}@{storage_account}.blob.core.windows.net\" \n",
    "\n",
    "\n",
    "# blob storage is mounted here.\n",
    "mids261_mount_path = \"/mnt/mids-w261\"\n",
    "\n",
    "# SAS Token: Grant the team limited access to Azure Storage resources\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net\",\n",
    "    dbutils.secrets.get(scope=secret_scope, key=secret_key),\n",
    ")\n",
    "\n",
    "# see what's in the blob storage root folder\n",
    "# display(dbutils.fs.ls(f\"{team_blob_url}\"))\n",
    "\n",
    "# mount\n",
    "data_BASE_DIR = \"dbfs:/mnt/mids-w261/\"\n",
    "# display(dbutils.fs.ls(f\"{data_BASE_DIR}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2277ba9d-b999-455e-9ca5-454dbe1dfc3a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46c77687-e56e-4d60-9b94-daf7fe883d6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#standard\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F \n",
    "import seaborn as sns\n",
    "\n",
    "# Boolean flags for sanity checks\n",
    "from pyspark.sql.types import BooleanType, ArrayType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d33f351-0d5f-4fcd-8eb6-1e0d3a4b6768",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load file\n",
    "- Uploaded .csv file from Google Drive to our blob via File --> Add data\n",
    "- Queried using SQL\n",
    "- Saved as Sparkdf\n",
    "- Saved as Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63b39927-b80d-43a6-86e9-20b4dbf22419",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM `hive_metastore`.`default`.`events_2015_2019_sheet_1`;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09f8eb43-3ab6-4e9f-a23b-0ec377ecd73a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events_2015_2019 = _sqldf\n",
    "events_2015_2019.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28edafa2-3b0e-4aba-9903-eb4769d708eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate a new dataframe with one row per date between start_date and end_date for each state\n",
    "exploded_dates = events_2015_2019.select(\"*\", F.explode(F.expr(\"sequence(to_date(start_date), to_date(end_date), interval 1 day)\")).alias(\"date\"))\n",
    "\n",
    "# Show the exploded dates DataFrame\n",
    "exploded_dates.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eac5d78d-7a9c-41ea-812a-609eb7236e96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events_2015_2019 = exploded_dates.select(\"event\", \"date\")\n",
    "events_2015_2019.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54433563-fbe7-416c-be19-abe6b08a8957",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Sanity checks\n",
    "1. Check that each event has 25 rows (5 per year, for 5 years)\n",
    "2. Check unique cases for event, to check for possible typos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b49f83f5-f3fc-4df7-9c45-389a19071080",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count the number of cases for each event\n",
    "case_counts = events_2015_2019.groupBy(\"event\").count()\n",
    "case_counts.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e249a7fe-9e6f-4acb-96bf-92cdd4779943",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Save Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0e6162a-ca22-443c-a48b-1db6c1fca59e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save as parquet file\n",
    "events_2015_2019.write.mode(\"overwrite\").parquet(f\"{team_blob_url}/5y_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ce612d7-daf7-432f-beea-f87f646cdb96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load checkpointed file\n",
    "events_2015_2019 = spark.read.parquet( f\"wasbs://{blob_container}@{storage_account}.blob.core.windows.net/5y_events\" )\n",
    "events_2015_2019.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3544923356432941,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Events 2015-2019",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
