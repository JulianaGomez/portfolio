{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93c6ef75-9bed-449e-9ddd-fff2fd6f1b33",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Gap analysis for ensemble \n",
    "\n",
    "Train: 2015-2018\n",
    "Test: 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bd88bd1-98ca-4f38-89b8-b9d9110f5d52",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "602635dd-fc92-445e-b49b-85b201415124",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "blob_container = \"261storagecontainer\"\n",
    "storage_account = \"261storage\"\n",
    "secret_scope = \"261_team_6_1_spring24_scope\"\n",
    "secret_key = \"team_6_1_key\"\n",
    "team_blob_url = f\"wasbs://{blob_container}@{storage_account}.blob.core.windows.net\"\n",
    "\n",
    "\n",
    "# blob storage is mounted here.\n",
    "mids261_mount_path = \"/mnt/mids-w261\"\n",
    "\n",
    "# SAS Token: Grant the team limited access to Azure Storage resources\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net\",\n",
    "    dbutils.secrets.get(scope=secret_scope, key=secret_key),\n",
    ")\n",
    "\n",
    "# see what's in the blob storage root folder\n",
    "# display(dbutils.fs.ls(f\"{team_blob_url}\"))\n",
    "\n",
    "# mount\n",
    "data_BASE_DIR = \"dbfs:/mnt/mids-w261/\"\n",
    "# display(dbutils.fs.ls(f\"{data_BASE_DIR}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be5c10b4-a298-4633-887d-493f2697f2b2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2b3951b-e9b3-430c-8bb7-011f38b5816a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install geopandas\n",
    "%pip install folium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffdbb022-364a-40f2-bcc9-2a822aa1d556",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "from hyperopt import hp, Trials, fmin, tpe, STATUS_OK\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F, DataFrame, Window\n",
    "from pyspark.sql.types import FloatType, DoubleType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.regression import (\n",
    "    LinearRegression,\n",
    "    DecisionTreeRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GBTRegressor,\n",
    ")\n",
    "from pyspark.ml.classification import LinearSVC, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.feature import (\n",
    "    VectorIndexer,\n",
    "    VectorAssembler,\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "# for maps\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from branca.element import Template, MacroElement\n",
    "\n",
    "# date handling\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c2f8405-93e4-4324-b6b2-934228d93d4a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Import Training and Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eaa1333-a80f-48b3-b263-bd4836bc4bb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def spark_shape(self):\n",
    "  \"\"\"Hack to emulate pandas' df.shape\"\"\"\n",
    "  display(self.count(), len(self.columns))\n",
    "\n",
    "\n",
    "def blob_read(subPath):\n",
    "  return spark.read.format(\"parquet\").option(\"header\", \"true\").load(f\"{team_blob_url}/{subPath}\")\n",
    "\n",
    "\n",
    "def blob_write(df, subPath):\n",
    "    df.write.mode(\"overwrite\").parquet(f\"{team_blob_url}/{subPath}\")\n",
    "\n",
    "os.environ[\"MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14cf09bf-147c-4387-985c-04b9f0d0a1c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"{team_blob_url}/MultilayerPerceptronClassifierEnsemble-2015\"))\n",
    "display(dbutils.fs.ls(f\"{team_blob_url}/LinearRegression-L2/2015-train\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3426cd2-e50a-44e3-93cb-603885c330db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation metrics for ensemble model (fbeta, precision, recall)\n",
    "model_name = \"MultilayerPerceptronClassifierEnsemble\"\n",
    "evaluation_df = blob_read(f\"{model_name}/evaluation\")\n",
    "# evaluation_df.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28d5aea1-2d13-4bc1-b7df-1a940beb0161",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_df =  blob_read(f\"{model_name}/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50887b49-ac9a-4f76-97b0-c291204233f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MultilayerPerceptronClassifierEnsemble-2015\n",
    "folds = [2015, 2016, 2017, 2018]\n",
    "\n",
    "train_outputs = [\n",
    "    \"MultilayerPerceptronClassifierEnsemble-{year}/train\",\n",
    "]\n",
    "\n",
    "validation_outputs = [\n",
    "    \"MultilayerPerceptronClassifierEnsemble-{year}/val\",\n",
    "]\n",
    "\n",
    "models = {}\n",
    "\n",
    "for year in folds:\n",
    "    models[year] = {}\n",
    "\n",
    "    for output in train_outputs:\n",
    "        model_name = output.split(\"-\")[0]\n",
    "        models[year][f\"{model_name}_train\"] = spark.read.parquet(\n",
    "            f\"{team_blob_url}/{output.format(year=year)}\"\n",
    "        ).withColumn(\"year\", F.lit(year))\n",
    "\n",
    "    for output in validation_outputs:\n",
    "        model_name = output.split(\"-\")[0]\n",
    "        models[year][f\"{model_name}_val\"] = spark.read.parquet(\n",
    "            f\"{team_blob_url}/{output.format(year=year)}\"\n",
    "        ).withColumn(\"year\", F.lit(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb20ecaf-c83f-478d-a28a-76502926ace4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "models[2018].keys()\n",
    "models[2018][\"MultilayerPerceptronClassifierEnsemble_train\"].limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91d6b4b9-5f51-44a7-8d2d-16ff40d39ebf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify that all models have the same columns\n",
    "reference_columns = list(\n",
    "    models[next(iter(models))][next(iter(models[next(iter(models))]))].columns\n",
    ")\n",
    "\n",
    "for year, model_dict in models.items():\n",
    "    for model_name, model_df in model_dict.items():\n",
    "        assert set(model_df.columns) == set(\n",
    "            reference_columns\n",
    "        ), f\"Column mismatch in {model_name} for year {year}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c72f8263-8413-4c95-aeb7-30c6d4f0f338",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "108ef07c-1cdb-44ef-a37e-4a385fd3476f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model_df, target_column=\"DEP_DEL15\", prediction_column=\"prediction\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates evaluation metrics for all classification models.\n",
    "\n",
    "    Args:\n",
    "        model_df: The DataFrame containing the model's predictions and target values.\n",
    "        target_column: Column with target values.\n",
    "        prediction_column: Column with model's predictions.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics (TP, FP, FN, TN, sum_check, precision, recall).\n",
    "    \"\"\"\n",
    "    TP = model_df.where(\n",
    "        (F.col(prediction_column) == 1) & (F.col(target_column) == 1)\n",
    "    ).count()\n",
    "    FP = model_df.where(\n",
    "        (F.col(prediction_column) == 1) & (F.col(target_column) == 0)\n",
    "    ).count()\n",
    "    FN = model_df.where(\n",
    "        (F.col(prediction_column) == 0) & (F.col(target_column) == 1)\n",
    "    ).count()\n",
    "    TN = model_df.where(\n",
    "        (F.col(prediction_column) == 0) & (F.col(target_column) == 0)\n",
    "    ).count()\n",
    "    sum_check = model_df.count()\n",
    "\n",
    "    if TP + FP == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = TP / (TP + FP)\n",
    "\n",
    "    if TP + FN == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = TP / (TP + FN)\n",
    "\n",
    "    return {\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN,\n",
    "        \"TN\": TN,\n",
    "        \"sum_check\": sum_check,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b6ae8ca-0df7-44c2-80c6-46c238ddb690",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_prediction_type(\n",
    "    model_df, target_column=\"DEP_DEL15\", prediction_column=\"prediction\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds a new column 'prediction_type' to the input DataFrame indicating TP, TN, FP, or FN.\n",
    "\n",
    "    Args:\n",
    "        model_df: The DataFrame containing the model's predictions and target values.\n",
    "        target_column: Column with target values.\n",
    "        prediction_column: Column with model's predictions.\n",
    "\n",
    "    Returns:\n",
    "        A Spark dataframe: The input DataFrame with a new column \"prediction_type\" indicating TP, TN, FP, or FN.\n",
    "    \"\"\"\n",
    "    return model_df.withColumn(\n",
    "        \"prediction_type\",\n",
    "        F.when((F.col(prediction_column) == 1) & (F.col(target_column) == 1), \"TP\")\n",
    "        .when((F.col(prediction_column) == 1) & (F.col(target_column) == 0), \"FP\")\n",
    "        .when((F.col(prediction_column) == 0) & (F.col(target_column) == 1), \"FN\")\n",
    "        .otherwise(\"TN\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e680fa01-39e6-481b-bb22-e8bf7015003a",
     "showTitle": true,
     "title": "Count cases of TP, TN, FP, FN"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Evaluation metrics for Ensemble model\")\n",
    "for year in folds:\n",
    "    for model_key in models[year].keys():\n",
    "        if \"_train\" in model_key:\n",
    "            train_metrics = evaluate_model(models[year][model_key])\n",
    "            print(f\"{year} Training Metrics:\")\n",
    "            print(train_metrics)\n",
    "        elif \"_val\" in model_key:\n",
    "            val_metrics = evaluate_model(models[year][model_key])\n",
    "            print(f\"{year} Validation Metrics:\")\n",
    "            print(val_metrics)\n",
    "            print(\"-\" * 100)\n",
    "            print()\n",
    "\n",
    "test_metrics = evaluate_model(test_df)\n",
    "print(f\"Test Metrics:\")\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d308a0ac-d0e3-4309-9e26-84d292293093",
     "showTitle": true,
     "title": "Add prediction_type column to all models"
    }
   },
   "outputs": [],
   "source": [
    "#training and validation\n",
    "for year in folds:\n",
    "    for model_key in models[year].keys():\n",
    "        if \"_train\" in model_key:\n",
    "            models[year][model_key] = add_prediction_type(models[year][model_key])\n",
    "        elif \"_val\" in model_key:\n",
    "            models[year][model_key] = add_prediction_type(models[year][model_key])\n",
    "\n",
    "#test \n",
    "test_df = add_prediction_type(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "362740f1-b89f-4aee-bd52-f3c716ba2493",
     "showTitle": true,
     "title": "Check prediction_type column"
    }
   },
   "outputs": [],
   "source": [
    "models[2015][\"MultilayerPerceptronClassifierEnsemble_train\"].where(\n",
    "    F.col(\"prediction_type\") == \"FP\"\n",
    ").select(\"DEP_DEL15\", \"prediction\", \"prediction_type\").limit(5).display()\n",
    "\n",
    "test_df.where(F.col(\"prediction_type\") == \"FP\").select(\n",
    "    \"DEP_DEL15\", \"prediction\", \"prediction_type\"\n",
    ").limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c676f7-def0-4a81-9198-33e052a47541",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0cd9297-493b-496d-9ba6-1ad8138feb7c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Compare percentage of TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d341da16-e6e9-41b6-bd70-dd4c44266649",
     "showTitle": true,
     "title": "Join all folds into train_df and val_df"
    }
   },
   "outputs": [],
   "source": [
    "train_df = spark.createDataFrame([], models[2015][\"MultilayerPerceptronClassifierEnsemble_train\"].schema)\n",
    "val_df = spark.createDataFrame([], models[2015][\"MultilayerPerceptronClassifierEnsemble_val\"].schema)\n",
    "\n",
    "for year, fold_data in models.items():\n",
    "    train_df_year = fold_data.get(\"MultilayerPerceptronClassifierEnsemble_train\")\n",
    "    val_df_year = fold_data.get(\"MultilayerPerceptronClassifierEnsemble_val\")\n",
    "\n",
    "    if train_df_year is None or val_df_year is None:\n",
    "        print(\n",
    "            f\"WARNING: DataFrames missing for year {year} and model MultilayerPerceptronClassifierEnsemble\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    train_df = train_df.union(train_df_year)\n",
    "    val_df = val_df.union(val_df_year)\n",
    "\n",
    "train_df.limit(5).display()\n",
    "val_df.limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7d5aaf3-dd99-4da7-9f6f-5fb373d6a005",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70c79d11-6ad6-4fb2-b047-2c85df130404",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "dbutils.fs.mkdirs(f\"{team_blob_url}/ensemble_dfs_w_pred_type\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cf6669c-eba6-425e-8654-68949a6ae6c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "blob_write(train_df,\"ensemble_dfs_w_pred_type\")\n",
    "blob_write(val_df,\"ensemble_dfs_w_pred_type\")\n",
    "blob_write(test_df,\"ensemble_dfs_w_pred_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fab2aeb-6df7-4f10-8cb4-2fee62d53c5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_SOURCE = \"ensemble_dfs_w_pred_type/train_df\"\n",
    "VAL_SOURCE = \"ensemble_dfs_w_pred_type/val_df\"\n",
    "TEST_SOURCE = \"ensemble_dfs_w_pred_type/test_df\"\n",
    "\n",
    "train_df = blob_read(TRAIN_SOURCE)\n",
    "val_df = blob_read(VAL_SOURCE)\n",
    "test_df = blob_read(TEST_SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8041dc8d-50ca-4564-a7f8-0cc806294fa0",
     "showTitle": true,
     "title": "Confusion matrices"
    }
   },
   "outputs": [],
   "source": [
    "# For Train\n",
    "confusion_matrix_train = train_df.groupBy(\"prediction_type\").count().withColumn(\n",
    "    \"Percentage\", F.col(\"count\") / F.sum(\"count\").over(Window.rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)) * 100\n",
    ").groupBy().pivot(\"prediction_type\").avg(\"Percentage\").na.fill(0)\n",
    "\n",
    "# For Validation\n",
    "confusion_matrix_val = val_df.groupBy(\"prediction_type\").count().withColumn(\n",
    "    \"Percentage\", F.col(\"count\") / F.sum(\"count\").over(Window.rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)) * 100\n",
    ").groupBy().pivot(\"prediction_type\").avg(\"Percentage\").na.fill(0)\n",
    "\n",
    "# For Test\n",
    "confusion_matrix_test = test_df.groupBy(\"prediction_type\").count().withColumn(\n",
    "    \"Percentage\", F.col(\"count\") / F.sum(\"count\").over(Window.rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)) * 100\n",
    ").groupBy().pivot(\"prediction_type\").avg(\"Percentage\").na.fill(0)\n",
    "\n",
    "# Plot the confusion matrices\n",
    "confusion_matrix_train_pandas = confusion_matrix_train.toPandas()\n",
    "confusion_matrix_val_pandas = confusion_matrix_val.toPandas()\n",
    "confusion_matrix_test_pandas = confusion_matrix_test.toPandas()\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(18, 6), sharex=True, sharey=True)\n",
    "\n",
    "sns.heatmap(confusion_matrix_train_pandas, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=axes[0])\n",
    "axes[0].set_title('Train')\n",
    "\n",
    "sns.heatmap(confusion_matrix_val_pandas, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=axes[1])\n",
    "axes[1].set_title('Validation')\n",
    "\n",
    "sns.heatmap(confusion_matrix_test_pandas, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=axes[2])\n",
    "axes[2].set_title('Test')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11313d74-f370-49b2-9588-c47e03d662e4",
     "showTitle": true,
     "title": "Percentage of cases with TP/TN/FP/FN in train, val and test"
    }
   },
   "outputs": [],
   "source": [
    "class_percentage_train_df = (\n",
    "    train_df.groupBy(\"FL_DATE\", \"prediction_type\")\n",
    "    .count()\n",
    "    .withColumn(\n",
    "        \"Percentage\",\n",
    "        F.col(\"count\") / (F.sum(\"count\").over(Window.partitionBy(\"FL_DATE\"))) * 100,\n",
    "    )\n",
    ")\n",
    "\n",
    "class_percentage_train_df.limit(1).display()\n",
    "\n",
    "\n",
    "class_percentage_val_df = (\n",
    "    val_df.groupBy(\"FL_DATE\", \"prediction_type\")\n",
    "    .count()\n",
    "    .withColumn(\n",
    "        \"Percentage\",\n",
    "        F.col(\"count\") / (F.sum(\"count\").over(Window.partitionBy(\"FL_DATE\"))) * 100,\n",
    "    )\n",
    ")\n",
    "\n",
    "class_percentage_val_df.limit(1).display()\n",
    "\n",
    "\n",
    "\n",
    "class_percentage_test_df = (\n",
    "    test_df.groupBy(\"FL_DATE\", \"prediction_type\")\n",
    "    .count()\n",
    "    .withColumn(\n",
    "        \"Percentage\",\n",
    "        F.col(\"count\") / (F.sum(\"count\").over(Window.partitionBy(\"FL_DATE\"))) * 100,\n",
    "    )\n",
    ")\n",
    "\n",
    "class_percentage_test_df.limit(1).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "289fed1a-d20f-4fd0-acc7-091f48610e3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Seasonalities - flags\n",
    "\n",
    "PLAN:\n",
    "\n",
    "- If the highest percentage for a day is FP/FN, and has a flag, add flag as annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "381cf5f7-b2aa-4a88-8673-e483377e748a",
     "showTitle": true,
     "title": "Create column where class FN prediction type was the most common for that day"
    }
   },
   "outputs": [],
   "source": [
    "# TRAINING--------------------------------------------------------------------------------\n",
    "\n",
    "# Calculate maximum Percentage for each FL_DATE\n",
    "class_percentage_train_df = class_percentage_train_df.withColumn(\n",
    "    \"max_percentage\",\n",
    "    F.max(\"Percentage\").over(Window.partitionBy(\"FL_DATE\")),\n",
    ")\n",
    "\n",
    "# Add max_pct_per_day column based on comparison with max_percentage\n",
    "class_percentage_train_df = class_percentage_train_df.withColumn(\n",
    "    \"max_pct_per_day\", (F.col(\"Percentage\") == F.col(\"max_percentage\")).cast(\"int\")\n",
    ")\n",
    "\n",
    "# Optional: Drop the temporary max_percentage column\n",
    "class_percentage_train_df = class_percentage_train_df.drop(\"max_percentage\")\n",
    "\n",
    "# VALIDATION--------------------------------------------------------------------------------\n",
    "class_percentage_val_df = class_percentage_val_df.withColumn(\n",
    "    \"max_percentage\",\n",
    "    F.max(\"Percentage\").over(Window.partitionBy(\"FL_DATE\")),\n",
    ")\n",
    "\n",
    "class_percentage_val_df = class_percentage_val_df.withColumn(\n",
    "    \"max_pct_per_day\", (F.col(\"Percentage\") == F.col(\"max_percentage\")).cast(\"int\")\n",
    ")\n",
    "\n",
    "class_percentage_val_df = class_percentage_val_df.drop(\"max_percentage\")\n",
    "\n",
    "\n",
    "# TEST--------------------------------------------------------------------------------\n",
    "class_percentage_test_df = class_percentage_test_df.withColumn(\n",
    "    \"max_percentage\",\n",
    "    F.max(\"Percentage\").over(Window.partitionBy(\"FL_DATE\")),\n",
    ")\n",
    "\n",
    "class_percentage_test_df = class_percentage_test_df.withColumn(\n",
    "    \"max_pct_per_day\", (F.col(\"Percentage\") == F.col(\"max_percentage\")).cast(\"int\")\n",
    ")\n",
    "\n",
    "class_percentage_test_df = class_percentage_test_df.drop(\"max_percentage\")\n",
    "\n",
    "class_percentage_train_df.limit(5).display()\n",
    "class_percentage_val_df.limit(5).display()\n",
    "class_percentage_test_df.limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8d8d2c7-abdf-44f6-a895-ef4c019f4d9d",
     "showTitle": true,
     "title": "Trends in FP/FN for training"
    }
   },
   "outputs": [],
   "source": [
    "# TRAINING------------------------------------------------------------------------------------\n",
    "fn_df = class_percentage_train_df.filter(F.col(\"prediction_type\") == \"FN\")\n",
    "fp_df = class_percentage_train_df.filter(F.col(\"prediction_type\") == \"FP\")\n",
    "\n",
    "fn_df = fn_df.toPandas()\n",
    "fp_df = fp_df.toPandas()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# FN\n",
    "ax.plot(fn_df[\"FL_DATE\"], fn_df[\"Percentage\"], color=\"orange\", label=\"FN\")\n",
    "ax.set_title(\"Percentage of FN and FP out of all flights for that day - training\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "# FP\n",
    "ax.plot(fp_df[\"FL_DATE\"], fp_df[\"Percentage\"], color=\"blue\", label=\"FP\")\n",
    "\n",
    "# Change date format\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator(bymonth=(1, 4, 7, 10)))\n",
    "\n",
    "# annotations\n",
    "holidays1 = datetime.date(2015, 12, 30)  \n",
    "holidays2 = datetime.date(2016, 12, 30)  \n",
    "holidays3 = datetime.date(2017, 12, 30)  \n",
    "holidays4 = datetime.date(2018, 12, 30)  \n",
    "\n",
    "ax.axvline(holidays1, color=\"gray\", linestyle=\"dotted\")\n",
    "ax.axvline(holidays2, color=\"gray\", linestyle=\"dotted\")\n",
    "ax.axvline(holidays3, color=\"gray\", linestyle=\"dotted\")\n",
    "ax.axvline(holidays4, color=\"gray\", linestyle=\"dotted\")\n",
    "\n",
    "ax.text(holidays1, 28, 'Holiday \\n season') \n",
    "ax.text(holidays2, 28, 'Holiday \\n season') \n",
    "ax.text(holidays3, 28, 'Holiday \\n season') \n",
    "ax.text(holidays4, 28, 'Holiday \\n season') \n",
    "\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0475b87d-e1d2-4e85-9cb1-1c4ba45a984d",
     "showTitle": true,
     "title": "Trends in FP/FN for validation"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION------------------------------------------------------------------------------------\n",
    "fn_df = class_percentage_val_df.filter(F.col(\"prediction_type\") == \"FN\")\n",
    "fp_df = class_percentage_val_df.filter(F.col(\"prediction_type\") == \"FP\")\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "fn_df = fn_df.toPandas()\n",
    "fp_df = fp_df.toPandas()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# FN\n",
    "ax.plot(fn_df[\"FL_DATE\"], fn_df[\"Percentage\"], color=\"orange\", label=\"FN\")\n",
    "ax.set_title(\"Percentage of FN and FP out of all flights for that day - validation\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "# FP\n",
    "ax.plot(fp_df[\"FL_DATE\"], fp_df[\"Percentage\"], color=\"blue\", label=\"FP\")\n",
    "\n",
    "# Change date format\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator(bymonth=(1, 4, 7, 10)))\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "389298f4-73c2-40d3-bf1e-1c1bcd9e6bfc",
     "showTitle": true,
     "title": "Trends in FP/FN for test"
    }
   },
   "outputs": [],
   "source": [
    "# TEST ------------------------------------------------------------------------------------\n",
    "fn_df = class_percentage_test_df.filter(F.col(\"prediction_type\") == \"FN\")\n",
    "fp_df = class_percentage_test_df.filter(F.col(\"prediction_type\") == \"FP\")\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "fn_df = fn_df.toPandas()\n",
    "fp_df = fp_df.toPandas()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# FN\n",
    "ax.plot(fn_df[\"FL_DATE\"], fn_df[\"Percentage\"], color=\"orange\", label=\"FN\")\n",
    "ax.set_title(\"Percentage of FN and FP out of all flights for that day  - test\")\n",
    "ax.set_xlabel(\"Date - 2019\")\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "# FP\n",
    "ax.plot(fp_df[\"FL_DATE\"], fp_df[\"Percentage\"], color=\"blue\", label=\"FP\")\n",
    "\n",
    "# change date format\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator(interval=5))\n",
    "\n",
    "#annotations\n",
    "thanksgiving = datetime.date(2019, 11, 30)  \n",
    "ax.axvline(thanksgiving, color=\"gray\", linestyle=\"dotted\")\n",
    "ax.text(thanksgiving, 22.1, 'Thanksgiving season') \n",
    "tornadoes = datetime.date(2019, 4, 14)  \n",
    "ax.axvline(tornadoes, color=\"gray\", linestyle=\"dotted\")\n",
    "ax.text(tornadoes, 21.5, 'Southern and Eastern Tornadoes \\n and Severe Weather')\n",
    "flooding = datetime.date(2019, 6, 20)  \n",
    "ax.axvline(flooding, color=\"gray\", linestyle=\"dotted\")\n",
    "ax.text(flooding, 22.1,'  ?')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1552051f-9125-4dee-9b7e-d8253526ebc9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "There doesn't seem to be much clustering around specific dates for the training set, but for the validation set, January 2017 seems to cluster a large number of false negatives. During this month, there was a severe tornado outbreak and western storms - look into whether delays were more higher in those states than usual for that month. For the test set, there is definitely a seasonal component to the false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6847f04c-5bf0-4989-9e71-22c8529122ae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Other variables (Based on 5YR_OTPW_s2.1_Overall_EDA notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea134b5e-6646-44be-9830-82165f5b1a04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "OUTCOME = [\"log_DEP_DELAY\", \"DEP_DELAY\", \"DEP_DEL15\"]  # original lable\n",
    "PREDICTIONS = [\"prediction\", \"PRED_DEP_DELAY\", \"PRED_DELAY15\"]  # prediction lables\n",
    "\n",
    "NUMERICAL = [\n",
    "    # \"HourlyWindDirection\",\n",
    "    \"HourlyRelativeHumidity\",\n",
    "    \"HourlyWindSpeed\",\n",
    "    # \"WindChill\",\n",
    "    # \"pca_time_distance\",\n",
    "    \"pca_elevation_station_pressure\",\n",
    "    # \"pca_altimeter_sea_level_pressure\",\n",
    "    \"pca_dew_windchill_wet_temp\",\n",
    "    \"pagerank\",\n",
    "    \"incoming_flight_delay_ratio\",\n",
    "    \"last_delay\",\n",
    "    \"log_average_delay\",\n",
    "    \"trend\",\n",
    "    \"yhat\",\n",
    "    # \"seasonality\",\n",
    "    # old ones, just to try\n",
    "    \"CRS_ELAPSED_TIME\",\n",
    "    \"DISTANCE\",\n",
    "    # \"ELEVATION\",\n",
    "    # \"HourlyStationPressure\",\n",
    "    \"HourlyAltimeterSetting\",\n",
    "    # \"HourlySeaLevelPressure\",\n",
    "    # \"HourlyDewPointTemperature\",\n",
    "    # \"HourlyDryBulbTemperature\",\n",
    "    # \"HourlyWetBulbTemperature\",\n",
    "]\n",
    "\n",
    "CATEGORICAL = [\n",
    "    \"origin_type\",\n",
    "    \"origin_region\",\n",
    "    # \"SkyDarkness\",\n",
    "    # \"CloudHeight\",\n",
    "    \"CloudHeightandDarkness\",\n",
    "    \"event_flag\",\n",
    "    \"drought_flag\",\n",
    "    \"flooding_flag\",\n",
    "    # \"freeze_flag\",\n",
    "    \"severe_storm_flag\",\n",
    "    \"tropical_cyclone_flag\",\n",
    "    \"wildfire_flag\",\n",
    "    \"winter_storm_flag\",\n",
    "    # old ones just to try\n",
    "    \"OP_UNIQUE_CARRIER\",\n",
    "    # \"TAIL_NUM\",\n",
    "    # \"OP_CARRIER_FL_NUM\",\n",
    "    \"ORIGIN\",\n",
    "    \"DEST\",\n",
    "    # \"origin_station_id\",\n",
    "    \"MONTH\",\n",
    "    \"DAY_OF_MONTH\",\n",
    "    \"DAY_OF_WEEK\",\n",
    "    # \"HourlySkyConditions\",\n",
    "]\n",
    "\n",
    "TIME = [\n",
    "    \"sched_depart_date_time\",\n",
    "    \"sched_depart_date_time_UTC\",\n",
    "    \"two_hours_prior_depart_UTC\",\n",
    "    \"four_hours_prior_depart_UTC\",\n",
    "    \"YEAR\",\n",
    "    \"QUARTER\",\n",
    "    \"MONTH\",\n",
    "    \"DAY_OF_MONTH\",\n",
    "    \"DAY_OF_WEEK\",\n",
    "    \"sched_arrive_date_time_UTC\",\n",
    "]\n",
    "\n",
    "FILTER = [\n",
    "    \"FL_DATE\",\n",
    "    # \"ORIGIN\",\n",
    "    # \"DEST\",\n",
    "    # \"OP_UNIQUE_CARRIER\",\n",
    "    \"TAIL_NUM\",\n",
    "    \"OP_CARRIER_FL_NUM\",\n",
    "    \"origin_station_id\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14216d72-3fa3-47a9-8b60-1866a5e6c339",
     "showTitle": true,
     "title": "Histogram of log_DEP_DELAY vs prediction_type - TRAINING"
    }
   },
   "outputs": [],
   "source": [
    "# TRAINING -----------------------------------------------------------------------------\n",
    "prediction_type_delay_df_train = train_df.select(\n",
    "    \"prediction_type\", \"log_DEP_DELAY\"\n",
    ").toPandas()\n",
    "\n",
    "prediction_type_categories = {\n",
    "    \"FN\": prediction_type_delay_df_train[\"prediction_type\"] == \"FN\",\n",
    "    \"FP\": prediction_type_delay_df_train[\"prediction_type\"] == \"FP\",\n",
    "    \"TN\": prediction_type_delay_df_train[\"prediction_type\"] == \"TN\",\n",
    "    \"TP\": prediction_type_delay_df_train[\"prediction_type\"] == \"TP\",\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8), sharex=True)\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for category_name, filter_condition in prediction_type_categories.items():\n",
    "    filtered_data = prediction_type_delay_df_train[filter_condition]\n",
    "    axs[row, col].hist(filtered_data[\"log_DEP_DELAY\"])\n",
    "    axs[row, col].set_xlabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_ylabel(\"Frequency\")\n",
    "    axs[row, col].set_title(f\"{category_name} - Log Departure Delay Distribution - Training\")\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72b050c6-9cda-4acc-b61e-be8dfe4833d6",
     "showTitle": true,
     "title": "Histogram of log_DEP_DELAY vs prediction_type - VALIDATION"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION -----------------------------------------------------------------------------\n",
    "\n",
    "prediction_type_delay_df_val = val_df.select(\n",
    "    \"prediction_type\", \"log_DEP_DELAY\"\n",
    ").toPandas()\n",
    "\n",
    "prediction_type_categories = {\n",
    "    \"FN\": prediction_type_delay_df_val[\"prediction_type\"] == \"FN\",\n",
    "    \"FP\": prediction_type_delay_df_val[\"prediction_type\"] == \"FP\",\n",
    "    \"TN\": prediction_type_delay_df_val[\"prediction_type\"] == \"TN\",\n",
    "    \"TP\": prediction_type_delay_df_val[\"prediction_type\"] == \"TP\",\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8), sharex=True)\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for category_name, filter_condition in prediction_type_categories.items():\n",
    "    filtered_data = prediction_type_delay_df_val[filter_condition]\n",
    "    axs[row, col].hist(filtered_data[\"log_DEP_DELAY\"])\n",
    "    axs[row, col].set_xlabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_ylabel(\"Frequency\")\n",
    "    axs[row, col].set_title(f\"{category_name} - Log Departure Delay Distribution - Validation\")\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66593ef4-178b-4adf-8f47-a55f8c9069e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TEST -----------------------------------------------------------------------------\n",
    "\n",
    "prediction_type_delay_df_test = test_df.select(\n",
    "    \"prediction_type\", \"log_DEP_DELAY\"\n",
    ").toPandas()\n",
    "\n",
    "prediction_type_categories = {\n",
    "    \"FN\": prediction_type_delay_df_test[\"prediction_type\"] == \"FN\",\n",
    "    \"FP\": prediction_type_delay_df_test[\"prediction_type\"] == \"FP\",\n",
    "    \"TN\": prediction_type_delay_df_test[\"prediction_type\"] == \"TN\",\n",
    "    \"TP\": prediction_type_delay_df_test[\"prediction_type\"] == \"TP\",\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8), sharex=True)\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for category_name, filter_condition in prediction_type_categories.items():\n",
    "    filtered_data = prediction_type_delay_df_test[filter_condition]\n",
    "    axs[row, col].hist(filtered_data[\"log_DEP_DELAY\"])\n",
    "    axs[row, col].set_xlabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_ylabel(\"Frequency\")\n",
    "    axs[row, col].set_title(f\"{category_name} - Log Departure Delay Distribution - Test\")\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e92bbff6-52f9-4b4e-b4fc-39436c6e5864",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "No aparent difference in distributions of log Delays between training, validation and test for all prediction types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e708cb0c-bf60-46d6-a777-da7abcf580a0",
     "showTitle": true,
     "title": "Distributions of delays by year and prediction type - training"
    }
   },
   "outputs": [],
   "source": [
    "# TRAINING -----------------------------------------------------------------------------\n",
    "year_delay_df = train_df.select([\"YEAR\", \"log_DEP_DELAY\", \"prediction_type\"]).toPandas()\n",
    "prediction_type_order = [\"FN\", \"FP\", \"TN\", \"TP\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = year_delay_df[year_delay_df[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"YEAR\",\n",
    "        y=\"log_DEP_DELAY\",\n",
    "        showmeans=True,\n",
    "        data=filtered_data,\n",
    "        ax=axs[row, col],\n",
    "    )\n",
    "\n",
    "    axs[row, col].set_xlabel(\"Year\")\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f\"Prediction Type: {pred_type} - Training\")\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ea295e2-99a1-40bf-816d-a3063bce8711",
     "showTitle": true,
     "title": "Distributions of delays by year and prediction type - validation"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION -----------------------------------------------------------------------------\n",
    "year_delay_df_val = val_df.select([\"YEAR\", \"log_DEP_DELAY\", \"prediction_type\"]).toPandas()\n",
    "prediction_type_order = [\"FN\", \"FP\", \"TN\", \"TP\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = year_delay_df_val[year_delay_df_val[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"YEAR\",\n",
    "        y=\"log_DEP_DELAY\",\n",
    "        showmeans=True,\n",
    "        data=filtered_data,\n",
    "        ax=axs[row, col],\n",
    "    )\n",
    "\n",
    "    axs[row, col].set_xlabel(\"Year\")\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f\"Prediction Type: {pred_type} - Validation\")\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12748b24-deed-4079-9922-24a5118987f4",
     "showTitle": true,
     "title": "Distributions of delays by year and prediction type - test"
    }
   },
   "outputs": [],
   "source": [
    "# TEST -----------------------------------------------------------------------------\n",
    "year_delay_df_test = test_df.select([\"log_DEP_DELAY\", \"prediction_type\"]).toPandas()\n",
    "prediction_type_order = [\"FN\", \"FP\", \"TN\", \"TP\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(4, 4))\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = year_delay_df_test[year_delay_df_test[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        y=\"log_DEP_DELAY\",\n",
    "        showmeans=True,\n",
    "        data=filtered_data,\n",
    "        ax=axs[row, col],\n",
    "    )\n",
    "\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f\"Prediction Type: {pred_type} - Test\")\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15dcf450-419a-4681-acc2-d52684aec287",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Visualize the correlation matrix for numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cebff093-dc88-46e6-9813-9d93fa5807cc",
     "showTitle": true,
     "title": "Correlation matrix between numerical variables and output - training"
    }
   },
   "outputs": [],
   "source": [
    "# TRAINING---------------------------------------------------------\n",
    "train_df.cache()\n",
    "\n",
    "prediction_types = train_df.select(\"prediction_type\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "numerical_columns = NUMERICAL\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for index, pred_type in enumerate(prediction_types):\n",
    "    subset_data = (\n",
    "        train_df.filter(train_df.prediction_type == pred_type)\n",
    "        .select([\"log_DEP_DELAY\"] + numerical_columns)\n",
    "        .toPandas()\n",
    "    )\n",
    "    \n",
    "    corr_matrix = subset_data.corr().round(2)\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    \n",
    "    heatmap = sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", mask=mask, ax=axs[index], square=True, cbar=False)\n",
    "    heatmap.set_xticklabels(heatmap.get_xticklabels(), ha='right')  \n",
    "    heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, ha='right')  \n",
    "    \n",
    "    axs[index].set_title(f\"Correlation Matrix for {pred_type} - Training\", fontsize=7) \n",
    "    \n",
    "    for label in axs[index].get_xticklabels():\n",
    "        label.set_fontsize(6)  \n",
    "    for label in axs[index].get_yticklabels():\n",
    "        label.set_fontsize(6)  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9313c152-860f-42cd-b8f9-4191f128854d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Some correlations are more evident in FP (vs TP):\n",
    "- `incoming_flight_delay_ratio` and `DISTANCE`\n",
    "\n",
    "\n",
    "Some correlations are more evident in FN (vs TN):\n",
    "- `log_average_delay` with `incoming_flight_delay_ratio` and `last_delay`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2029d32-63a5-476c-b709-e81821f47a94",
     "showTitle": true,
     "title": "Correlation matrix between numerical variables and output - validation"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION---------------------------------------------------------\n",
    "val_df.cache()\n",
    "\n",
    "prediction_types = val_df.select(\"prediction_type\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "numerical_columns = NUMERICAL\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for index, pred_type in enumerate(prediction_types):\n",
    "    subset_data = (\n",
    "        val_df.filter(val_df.prediction_type == pred_type)\n",
    "        .select([\"log_DEP_DELAY\"] + numerical_columns)\n",
    "        .toPandas()\n",
    "    )\n",
    "    \n",
    "    corr_matrix = subset_data.corr().round(2)\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    \n",
    "    heatmap = sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", mask=mask, ax=axs[index], square=True, cbar=False)\n",
    "    heatmap.set_xticklabels(heatmap.get_xticklabels(), ha='right')  \n",
    "    heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, ha='right')  \n",
    "    \n",
    "    axs[index].set_title(f\"Correlation Matrix for {pred_type} - Validation\", fontsize=7) \n",
    "    \n",
    "    for label in axs[index].get_xticklabels():\n",
    "        label.set_fontsize(6)  \n",
    "    for label in axs[index].get_yticklabels():\n",
    "        label.set_fontsize(6)  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1b09136-a30a-45bb-af2b-b71988d50d61",
     "showTitle": true,
     "title": "Correlation matrix between numerical variables and output - test"
    }
   },
   "outputs": [],
   "source": [
    "# TEST---------------------------------------------------------\n",
    "test_df.cache()\n",
    "\n",
    "prediction_types = test_df.select(\"prediction_type\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "numerical_columns = NUMERICAL\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for index, pred_type in enumerate(prediction_types):\n",
    "    subset_data = (\n",
    "        test_df.filter(test_df.prediction_type == pred_type)\n",
    "        .select([\"log_DEP_DELAY\"] + numerical_columns)\n",
    "        .toPandas()\n",
    "    )\n",
    "    \n",
    "    corr_matrix = subset_data.corr().round(2)\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    \n",
    "    heatmap = sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", mask=mask, ax=axs[index], square=True, cbar=False)\n",
    "    heatmap.set_xticklabels(heatmap.get_xticklabels(), ha='right')  \n",
    "    heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, ha='right')  \n",
    "    \n",
    "    axs[index].set_title(f\"Correlation Matrix for {pred_type} - Test\", fontsize=7) \n",
    "    \n",
    "    for label in axs[index].get_xticklabels():\n",
    "        label.set_fontsize(6)  \n",
    "    for label in axs[index].get_yticklabels():\n",
    "        label.set_fontsize(6)  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb0ae00b-afdf-4f05-8dc0-7b444bf8e3b1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Similar correlations in TP/FP and TN/FN in training, validation and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2757c988-c882-49b7-8b44-46ccc3700087",
     "showTitle": true,
     "title": "Boxplot of log delay by unique carrier and prediction type - training"
    }
   },
   "outputs": [],
   "source": [
    "# TRAINING---------------------------------------------------------\n",
    "nominal_df = train_df.select(\n",
    "    \"OP_UNIQUE_CARRIER\", \"log_DEP_DELAY\", \"prediction_type\"\n",
    ").toPandas()\n",
    "prediction_type_order = [\"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "nominal_df = nominal_df.sort_values(by=\"OP_UNIQUE_CARRIER\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8), sharey = True)\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = nominal_df[nominal_df[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"OP_UNIQUE_CARRIER\",\n",
    "        y=\"log_DEP_DELAY\",\n",
    "        showmeans=True,\n",
    "        data=filtered_data,\n",
    "        ax=axs[row, col],\n",
    "    )\n",
    "\n",
    "    axs[row, col].set_xlabel(\"Unique Carrier\")\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f\"Prediction Type: {pred_type} - Training\")\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb1762aa-8bad-48b0-ab4f-ca1970f0be2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- Different distribution for `HA` and `WN`in TP vs FP \n",
    "- And also somewhat in `AS` and `B6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4b13648-ac00-46a6-ab5d-a35d1fbdf080",
     "showTitle": true,
     "title": "Boxplot of log delay by unique carrier and prediction type - validation"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION---------------------------------------------------------\n",
    "nominal_df_val = val_df.select(\"OP_UNIQUE_CARRIER\", \"log_DEP_DELAY\", \"prediction_type\").toPandas()\n",
    "prediction_type_order = [\"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "nominal_df_val = nominal_df_val.sort_values(by=\"OP_UNIQUE_CARRIER\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8), sharey = True)\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = nominal_df_val[nominal_df_val[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"OP_UNIQUE_CARRIER\", y=\"log_DEP_DELAY\", showmeans=True, data=filtered_data, ax=axs[row, col]\n",
    "    )  \n",
    "\n",
    "    axs[row, col].set_xlabel('Unique Carrier')\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f'Prediction Type: {pred_type} - Validation')\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5ce77ed-915d-4cab-8e1f-c771af627c1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TEST---------------------------------------------------------\n",
    "nominal_df_test = test_df.select(\"OP_UNIQUE_CARRIER\", \"log_DEP_DELAY\", \"prediction_type\").toPandas()\n",
    "prediction_type_order = [\"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "nominal_df_test = nominal_df_val.sort_values(by=\"OP_UNIQUE_CARRIER\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8),sharey=True)\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = nominal_df_test[nominal_df_test[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"OP_UNIQUE_CARRIER\", y=\"log_DEP_DELAY\", showmeans=True, data=filtered_data, ax=axs[row, col]\n",
    "    )  \n",
    "\n",
    "    axs[row, col].set_xlabel('Unique Carrier')\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f'Prediction Type: {pred_type} - Test')\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d490a45-bfba-46da-b883-4b7eb14ecdb0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- `A6` and `NH` rank different in FP validation than FP training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c41b586-1645-4a3b-8ae9-07f4fcaefb40",
     "showTitle": true,
     "title": "Boxplot of log delay by airport type and prediction type - training"
    }
   },
   "outputs": [],
   "source": [
    "# TRAINING ---------------------------------------------------------\n",
    "nominal_df = train_df.select(\"origin_type\", \"log_DEP_DELAY\", \"prediction_type\").toPandas()\n",
    "prediction_type_order = [\"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "nominal_df = nominal_df.sort_values(by=\"origin_type\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8),sharey=True)\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = nominal_df[nominal_df[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"origin_type\", y=\"log_DEP_DELAY\", showmeans=True, data=filtered_data, ax=axs[row, col]\n",
    "    )  \n",
    "\n",
    "    axs[row, col].set_xlabel('Origin Type')\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f'Prediction Type: {pred_type} - Training')\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0572c190-7b1a-4343-9dbe-dea200920ccb",
     "showTitle": true,
     "title": "Boxplot of log delay by airport type and prediction type - validation"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION---------------------------------------------------------\n",
    "nominal_df_val = val_df.select(\"origin_type\", \"log_DEP_DELAY\", \"prediction_type\").toPandas()\n",
    "prediction_type_order = [\"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "nominal_df_val = nominal_df_val.sort_values(by=\"origin_type\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8), sharey = True)\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = nominal_df_val[nominal_df_val[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"origin_type\", y=\"log_DEP_DELAY\", showmeans=True, data=filtered_data, ax=axs[row, col]\n",
    "    )  \n",
    "\n",
    "    axs[row, col].set_xlabel('Origin Type')\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f'Prediction Type: {pred_type} - Validation')\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d1771e4-387a-47a5-9ecc-20acfd71e923",
     "showTitle": true,
     "title": "airport - test"
    }
   },
   "outputs": [],
   "source": [
    "# TEST---------------------------------------------------------\n",
    "nominal_df_test = test_df.select(\"origin_type\", \"log_DEP_DELAY\", \"prediction_type\").toPandas()\n",
    "prediction_type_order = [\"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "nominal_df_test = nominal_df_test.sort_values(by=\"origin_type\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8),sharey = True)\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = nominal_df_test[nominal_df_test[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"origin_type\", y=\"log_DEP_DELAY\", showmeans=True, data=filtered_data, ax=axs[row, col]\n",
    "    )  \n",
    "\n",
    "    axs[row, col].set_xlabel('Origin Type')\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f'Prediction Type: {pred_type} - Test')\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a225da3d-350c-43f5-8870-2115006e55c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "No aparent different in origin type in training / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "936fd6bc-7848-4e78-ad73-7a9dac18e086",
     "showTitle": true,
     "title": "Boxplot of log delay by origin region and prediction type - training"
    }
   },
   "outputs": [],
   "source": [
    "# TRAINING---------------------------------------------------------\n",
    "nominal_df = train_df.select(\"origin_region\", \"log_DEP_DELAY\", \"prediction_type\").toPandas()\n",
    "prediction_type_order = [\"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "nominal_df = nominal_df.sort_values(by=\"origin_region\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = nominal_df[nominal_df[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"origin_region\", y=\"log_DEP_DELAY\", showmeans=True, data=filtered_data, ax=axs[row, col]\n",
    "    )  \n",
    "\n",
    "    axs[row, col].set_xlabel('Origin Region')\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f'Prediction Type: {pred_type} - Training')\n",
    "    axs[row, col].set_xticklabels(axs[row, col].get_xticklabels(), rotation=45) \n",
    "\n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfc23dff-8a8a-4184-8d3d-43302184447f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Difference in distribution for `US-MN`, `US-CO` and `US-NJ` in TP vs FP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d08d6783-04b4-40ad-a6dd-dffbaf6d3eef",
     "showTitle": true,
     "title": "Boxplot of log delay by origin region and prediction type - validation"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION---------------------------------------------------------\n",
    "nominal_df_val = val_df.select(\"origin_region\", \"log_DEP_DELAY\", \"prediction_type\").toPandas()\n",
    "prediction_type_order = [\"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "nominal_df_val = nominal_df_val.sort_values(by=\"origin_region\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = nominal_df_val[nominal_df_val[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"origin_region\", y=\"log_DEP_DELAY\", showmeans=True, data=filtered_data, ax=axs[row, col]\n",
    "    )  \n",
    "\n",
    "    axs[row, col].set_xlabel('Origin Region')\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f'Prediction Type: {pred_type} - Validation')\n",
    "    axs[row, col].set_xticklabels(axs[row, col].get_xticklabels(), rotation=45) \n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c45d8911-13c6-4b87-9934-92fddc5eb8cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TEST ---------------------------------------------------------\n",
    "nominal_df_test = val_df.select(\"origin_region\", \"log_DEP_DELAY\", \"prediction_type\").toPandas()\n",
    "prediction_type_order = [\"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "nominal_df_test = nominal_df_test.sort_values(by=\"origin_region\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "for pred_type in prediction_type_order:\n",
    "    filtered_data = nominal_df_test[nominal_df_test[\"prediction_type\"] == pred_type]\n",
    "    sns.boxplot(\n",
    "        x=\"origin_region\", y=\"log_DEP_DELAY\", showmeans=True, data=filtered_data, ax=axs[row, col]\n",
    "    )  \n",
    "\n",
    "    axs[row, col].set_xlabel('Origin Region')\n",
    "    axs[row, col].set_ylabel(\"Departure Delay (log mins)\")\n",
    "    axs[row, col].set_title(f'Prediction Type: {pred_type} - Test')\n",
    "    axs[row, col].set_xticklabels(axs[row, col].get_xticklabels(), rotation=45) \n",
    "\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c50d560f-5a5a-4004-994b-48fcde94c98f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Similar distribution to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f39d7948-d9b6-46a0-baaf-ab5f5e1a9489",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- Homogeneous distributions for all cloud layers in TP/ FP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d565f9ef-8ff4-47a7-9774-486c15b3f3e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 5. Sample cases of FP / FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10c40f36-b300-4982-97f0-3875be5d6ff1",
     "showTitle": true,
     "title": "Create dataframes with % of FN and FP for training and validation"
    }
   },
   "outputs": [],
   "source": [
    "# FN - TRAINING------------------------------------------------------------------------------------------------------\n",
    "fn_percentage_df_train = (\n",
    "    train_df.withColumn(\"state\", F.split(F.col(\"origin_region\"), \"-\").getItem(1))\n",
    "    .groupBy(\"state\")\n",
    "    .agg(\n",
    "        F.count(F.when(F.col(\"prediction_type\") == \"FN\", True)).alias(\"total_FN\"),\n",
    "        F.count(\"*\").alias(\"total_rows\"),\n",
    "    )\n",
    "    .withColumn(\"percentage_FN\", (F.col(\"total_FN\") / F.col(\"total_rows\")) * 100)\n",
    "    .select(\"state\", \"total_FN\", \"percentage_FN\")\n",
    ")\n",
    "\n",
    "\n",
    "# FP - TRAINING------------------------------------------------------------------------------------------------------\n",
    "fp_percentage_df_train = (\n",
    "    train_df.withColumn(\"state\", F.split(F.col(\"origin_region\"), \"-\").getItem(1))\n",
    "    .groupBy(\"state\")\n",
    "    .agg(\n",
    "        F.count(F.when(F.col(\"prediction_type\") == \"FP\", True)).alias(\"total_FP\"),\n",
    "        F.count(\"*\").alias(\"total_rows\"),\n",
    "    )\n",
    "    .withColumn(\"percentage_FP\", (F.col(\"total_FP\") / F.col(\"total_rows\")) * 100)\n",
    "    .select(\"state\", \"total_FP\", \"percentage_FP\")\n",
    ")\n",
    "\n",
    "\n",
    "# FN - VALIDATION------------------------------------------------------------------------------------------------------\n",
    "fn_percentage_df_val = (\n",
    "    val_df.withColumn(\"state\", F.split(F.col(\"origin_region\"), \"-\").getItem(1))\n",
    "    .groupBy(\"state\")\n",
    "    .agg(\n",
    "        F.count(F.when(F.col(\"prediction_type\") == \"FN\", True)).alias(\"total_FN\"),\n",
    "        F.count(\"*\").alias(\"total_rows\"),\n",
    "    )\n",
    "    .withColumn(\"percentage_FN\", (F.col(\"total_FN\") / F.col(\"total_rows\")) * 100)\n",
    "    .select(\"state\", \"total_FN\", \"percentage_FN\")\n",
    ")\n",
    "\n",
    "# FP - VALIDATION------------------------------------------------------------------------------------------------------\n",
    "fp_percentage_df_val = (\n",
    "    val_df.withColumn(\"state\", F.split(F.col(\"origin_region\"), \"-\").getItem(1))\n",
    "    .groupBy(\"state\")\n",
    "    .agg(\n",
    "        F.count(F.when(F.col(\"prediction_type\") == \"FP\", True)).alias(\"total_FP\"),\n",
    "        F.count(\"*\").alias(\"total_rows\"),\n",
    "    )\n",
    "    .withColumn(\"percentage_FP\", (F.col(\"total_FP\") / F.col(\"total_rows\")) * 100)\n",
    "    .select(\"state\", \"total_FP\", \"percentage_FP\")\n",
    ")\n",
    "\n",
    "\n",
    "# FN - TEST ------------------------------------------------------------------------------------------------------\n",
    "fn_percentage_df_test = (\n",
    "    val_df.withColumn(\"state\", F.split(F.col(\"origin_region\"), \"-\").getItem(1))\n",
    "    .groupBy(\"state\")\n",
    "    .agg(\n",
    "        F.count(F.when(F.col(\"prediction_type\") == \"FN\", True)).alias(\"total_FN\"),\n",
    "        F.count(\"*\").alias(\"total_rows\"),\n",
    "    )\n",
    "    .withColumn(\"percentage_FN\", (F.col(\"total_FN\") / F.col(\"total_rows\")) * 100)\n",
    "    .select(\"state\", \"total_FN\", \"percentage_FN\")\n",
    ")\n",
    "# FP - TEST------------------------------------------------------------------------------------------------------\n",
    "fp_percentage_df_test = (\n",
    "    val_df.withColumn(\"state\", F.split(F.col(\"origin_region\"), \"-\").getItem(1))\n",
    "    .groupBy(\"state\")\n",
    "    .agg(\n",
    "        F.count(F.when(F.col(\"prediction_type\") == \"FP\", True)).alias(\"total_FP\"),\n",
    "        F.count(\"*\").alias(\"total_rows\"),\n",
    "    )\n",
    "    .withColumn(\"percentage_FP\", (F.col(\"total_FP\") / F.col(\"total_rows\")) * 100)\n",
    "    .select(\"state\", \"total_FP\", \"percentage_FP\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e99e978-08b3-4049-9c2c-7c5724fe844d",
     "showTitle": true,
     "title": "Read geo_json file for states from blob"
    }
   },
   "outputs": [],
   "source": [
    "url = (\"https://eric.clst.org/assets/wiki/uploads/Stuff/gz_2010_us_040_00_20m.json\")\n",
    "\n",
    "# We read the file and print it.\n",
    "geoJSON_df = gpd.read_file(url)\n",
    "\n",
    "\n",
    "geoJSON_df['NAME'] = geoJSON_df['NAME'].str.strip()\n",
    "geoJSON_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84bcbfe8-ce77-482c-a6b1-d32a2ae0aa29",
     "showTitle": true,
     "title": "Load us states abbreviation file"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM `hive_metastore`.`default`.`us_states_territories`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feec1ebd-08cf-4142-ba08-051adbf36ad9",
     "showTitle": true,
     "title": "Join fn_percentage_df to geodata - training"
    }
   },
   "outputs": [],
   "source": [
    "# Load csv for US states and territories\n",
    "states = _sqldf    # Original code line\n",
    "states_df = states.toPandas()\n",
    "states_df['Name'] = states_df['Name'].str.strip()\n",
    "\n",
    "# Left join geoJSON_df on NAME with states_df on Name\n",
    "joined_df = geoJSON_df.merge(states_df, left_on='NAME', right_on='Name', how='left')\n",
    "joined_df['Abbreviation'] = joined_df['Abbreviation'].str.strip()\n",
    "\n",
    "\n",
    "# FN - TRAINING----------------------------------------------------------------------------------------------------------\n",
    "fn_percentage_pandas = fn_percentage_df_train.toPandas()\n",
    "fn_percentage_pandas.head()\n",
    "fn_percentage_pandas['state'] = fn_percentage_pandas['state'].str.strip()\n",
    "geo_fn_percentage_training = fn_percentage_pandas.merge(joined_df, left_on='state', right_on='Abbreviation', how='left')\n",
    "geo_fn_percentage_training.head()\n",
    "\n",
    "# FP - TRAINING----------------------------------------------------------------------------------------------------------\n",
    "fp_percentage_pandas = fp_percentage_df_train.toPandas()\n",
    "fp_percentage_pandas.head()\n",
    "fp_percentage_pandas['state'] = fp_percentage_pandas['state'].str.strip()\n",
    "geo_fp_percentage_training = fp_percentage_pandas.merge(joined_df, left_on='state', right_on='Abbreviation', how='left')\n",
    "\n",
    "\n",
    "# FN - validation----------------------------------------------------------------------------------------------------------\n",
    "fn_percentage_pandas_val = fn_percentage_df_val.toPandas()\n",
    "fn_percentage_pandas_val.head()\n",
    "fn_percentage_pandas_val['state'] = fn_percentage_pandas_val['state'].str.strip()\n",
    "geo_fn_percentage_val = fn_percentage_pandas_val.merge(joined_df, left_on='state', right_on='Abbreviation', how='left')\n",
    "geo_fn_percentage_val.head()\n",
    "\n",
    "# FP - TRAINING----------------------------------------------------------------------------------------------------------\n",
    "fp_percentage_pandas_val = fp_percentage_df_val.toPandas()\n",
    "fp_percentage_pandas_val.head()\n",
    "fp_percentage_pandas_val['state'] = fp_percentage_pandas_val['state'].str.strip()\n",
    "geo_fp_percentage_val = fp_percentage_pandas_val.merge(joined_df, left_on='state', right_on='Abbreviation', how='left')\n",
    "geo_fp_percentage_val.head()\n",
    "\n",
    "# FN - TEST----------------------------------------------------------------------------------------------------------\n",
    "fn_percentage_pandas_test = fn_percentage_df_test.toPandas()\n",
    "fn_percentage_pandas_test.head()\n",
    "fn_percentage_pandas_test['state'] = fn_percentage_pandas_test['state'].str.strip()\n",
    "geo_fn_percentage_test = fn_percentage_pandas_test.merge(joined_df, left_on='state', right_on='Abbreviation', how='left')\n",
    "geo_fn_percentage_test.head()\n",
    "\n",
    "# FP - TEST----------------------------------------------------------------------------------------------------------\n",
    "fp_percentage_pandas_test = fp_percentage_df_test.toPandas()\n",
    "fp_percentage_pandas_test.head()\n",
    "fp_percentage_pandas_test['state'] = fp_percentage_pandas_test['state'].str.strip()\n",
    "geo_fp_percentage_test = fp_percentage_pandas_test.merge(joined_df, left_on='state', right_on='Abbreviation', how='left')\n",
    "geo_fp_percentage_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73767138-09fb-4ef4-b16d-2d8f1b2bcac8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn_percentage_pandas.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9005f876-0b99-4b9d-9ade-127717f176fb",
     "showTitle": true,
     "title": "FN  - training"
    }
   },
   "outputs": [],
   "source": [
    "# map centered on the US\n",
    "map_fn_percentage = folium.Map(location=[39.50, -98.35], zoom_start=4)\n",
    "\n",
    "#chose based on 75% percentile of distribution\n",
    "def get_color(percentage):\n",
    "    \"\"\"\n",
    "    Produces color based on range of % FN\n",
    "    \"\"\"\n",
    "    if percentage >= 23:\n",
    "        return \"#e92658\"\n",
    "    else:\n",
    "        return \"#ef9816\"\n",
    "\n",
    "\n",
    "for index, row in geo_fn_percentage_training.iterrows():\n",
    "    state = row[\"state\"]\n",
    "    percentage_FN = row[\"percentage_FN\"]\n",
    "    color = get_color(percentage_FN)\n",
    "\n",
    "    # Create a GeoJson overlay for each state if the geometry is not None\n",
    "    if row[\"geometry\"]:\n",
    "        folium.GeoJson(\n",
    "            row[\"geometry\"],\n",
    "            style_function=lambda x, color=color: {\n",
    "                \"fillColor\": color,\n",
    "                \"color\": \"black\",\n",
    "                \"weight\": 2,\n",
    "                \"fillOpacity\": 0.8,\n",
    "            },\n",
    "        ).add_to(map_fn_percentage)\n",
    "\n",
    "\n",
    "# Add a legend\n",
    "template = \"\"\"\n",
    "{% macro html(this, kwargs) %}\n",
    "<div style=\"position: fixed;\n",
    "     bottom: 50px; left: 50px; width: 130px; height: 100px;\n",
    "     border:2px solid grey; z-index:9999; font-size:12px;\n",
    "     background-color: white;\n",
    "     opacity: 0.9;\n",
    "     \">\n",
    "     <p style=\"margin-left: 5px;\">Percentage of FN per state - training</p>\n",
    "     <ul style=\"list-style-type:none; padding-left: 5px;\">\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#e92658\"></i> >= 23%</li>\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#ef9816\"></i> < 23%</li>\n",
    "     </ul>\n",
    "</div>\n",
    "{% endmacro %}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "macro = MacroElement()\n",
    "macro._template = Template(template)\n",
    "\n",
    "map_fn_percentage.get_root().add_child(macro)\n",
    "\n",
    "# Display the map\n",
    "map_fn_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a59a3ce-ed46-41c3-a75c-04e8bb74b24b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fp_percentage_pandas.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef1e3b55-191b-464d-9fae-9d9f212207c8",
     "showTitle": true,
     "title": "FP - training"
    }
   },
   "outputs": [],
   "source": [
    "# map centered on the US\n",
    "map_fp_percentage = folium.Map(location=[39.50, -98.35], zoom_start=4)\n",
    "\n",
    "#chose value based on 75% percentile of distribution\n",
    "def get_color(percentage):\n",
    "    \"\"\"\n",
    "    Produces color based on range of % FP\n",
    "    \"\"\"\n",
    "    if percentage >= 9:\n",
    "        return \"#008f86\"\n",
    "    else:\n",
    "        return \"#69dab3\"\n",
    "\n",
    "\n",
    "for index, row in geo_fp_percentage_training.iterrows():\n",
    "    state = row[\"state\"]\n",
    "    percentage_FP = row[\"percentage_FP\"]\n",
    "    color = get_color(percentage_FP)\n",
    "\n",
    "    # Create a GeoJson overlay for each state if the geometry is not None\n",
    "    if row[\"geometry\"]:\n",
    "        folium.GeoJson(\n",
    "            row[\"geometry\"],\n",
    "            style_function=lambda x, color=color: {\n",
    "                \"fillColor\": color,\n",
    "                \"color\": \"black\",\n",
    "                \"weight\": 2,\n",
    "                \"fillOpacity\": 0.8,\n",
    "            },\n",
    "        ).add_to(map_fp_percentage)\n",
    "\n",
    "\n",
    "# Add a legend\n",
    "template = \"\"\"\n",
    "{% macro html(this, kwargs) %}\n",
    "<div style=\"position: fixed;\n",
    "     bottom: 50px; left: 50px; width: 130px; height: 100px;\n",
    "     border:2px solid grey; z-index:9999; font-size:12px;\n",
    "     background-color: white;\n",
    "     opacity: 0.9;\n",
    "     \">\n",
    "     <p style=\"margin-left: 5px;\">Percentage of FP per state - training</p>\n",
    "     <ul style=\"list-style-type:none; padding-left: 5px;\">\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#008f86\"></i> >= 9%</li>\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#69dab3\"></i> < 9%</li>\n",
    "     </ul>\n",
    "</div>\n",
    "{% endmacro %}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "macro = MacroElement()\n",
    "macro._template = Template(template)\n",
    "\n",
    "map_fp_percentage.get_root().add_child(macro)\n",
    "\n",
    "# Display the map\n",
    "map_fp_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fb062b2-3170-465b-b728-30e9c9a91774",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn_percentage_pandas_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5da23758-ba93-47d3-88c6-482cf0e69867",
     "showTitle": true,
     "title": "FN - validation"
    }
   },
   "outputs": [],
   "source": [
    "# map centered on the US\n",
    "map_fn_percentage = folium.Map(location=[39.50, -98.35], zoom_start=4)\n",
    "\n",
    "#chose value for 75% as cut-off\n",
    "def get_color(percentage):\n",
    "    \"\"\"\n",
    "    Produces color based on range of % FN\n",
    "    \"\"\"\n",
    "    if percentage >= 15:\n",
    "        return \"#e92658\"\n",
    "    else:\n",
    "        return \"#ef9816\"\n",
    "\n",
    "\n",
    "for index, row in geo_fn_percentage_val.iterrows():\n",
    "    state = row[\"state\"]\n",
    "    percentage_FN = row[\"percentage_FN\"]\n",
    "    color = get_color(percentage_FN)\n",
    "\n",
    "    # Create a GeoJson overlay for each state if the geometry is not None\n",
    "    if row[\"geometry\"]:\n",
    "        folium.GeoJson(\n",
    "            row[\"geometry\"],\n",
    "            style_function=lambda x, color=color: {\n",
    "                \"fillColor\": color,\n",
    "                \"color\": \"black\",\n",
    "                \"weight\": 2,\n",
    "                \"fillOpacity\": 0.8,\n",
    "            },\n",
    "        ).add_to(map_fn_percentage)\n",
    "\n",
    "\n",
    "# Add a legend\n",
    "template = \"\"\"\n",
    "{% macro html(this, kwargs) %}\n",
    "<div style=\"position: fixed;\n",
    "     bottom: 50px; left: 50px; width: 130px; height: 100px;\n",
    "     border:2px solid grey; z-index:9999; font-size:12px;\n",
    "     background-color: white;\n",
    "     opacity: 0.9;\n",
    "     \">\n",
    "     <p style=\"margin-left: 5px;\">Percentage of FN per state - validation</p>\n",
    "     <ul style=\"list-style-type:none; padding-left: 5px;\">\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#e92658\"></i> >= 15%</li>\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#ef9816\"></i> < 15%</li>\n",
    "     </ul>\n",
    "</div>\n",
    "{% endmacro %}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "macro = MacroElement()\n",
    "macro._template = Template(template)\n",
    "\n",
    "map_fn_percentage.get_root().add_child(macro)\n",
    "\n",
    "# Display the map\n",
    "map_fn_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ead42fb-440b-48ab-9a2a-0e5823d8b04e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fp_percentage_pandas_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4ddfc92-2ee0-47c2-a5cb-6d5238ab3f06",
     "showTitle": true,
     "title": "FP - validation"
    }
   },
   "outputs": [],
   "source": [
    "# map centered on the US\n",
    "map_fp_percentage = folium.Map(location=[39.50, -98.35], zoom_start=4)\n",
    "\n",
    "#chose value based on 75% percentile of distribution\n",
    "def get_color(percentage):\n",
    "    \"\"\"\n",
    "    Produces color based on range of % FP\n",
    "    \"\"\"\n",
    "    if percentage >= 15:\n",
    "        return \"#008f86\"\n",
    "    else:\n",
    "        return \"#69dab3\"\n",
    "\n",
    "\n",
    "for index, row in geo_fp_percentage_val.iterrows():\n",
    "    state = row[\"state\"]\n",
    "    percentage_FP = row[\"percentage_FP\"]\n",
    "    color = get_color(percentage_FP)\n",
    "\n",
    "    # Create a GeoJson overlay for each state if the geometry is not None\n",
    "    if row[\"geometry\"]:\n",
    "        folium.GeoJson(\n",
    "            row[\"geometry\"],\n",
    "            style_function=lambda x, color=color: {\n",
    "                \"fillColor\": color,\n",
    "                \"color\": \"black\",\n",
    "                \"weight\": 2,\n",
    "                \"fillOpacity\": 0.8,\n",
    "            },\n",
    "        ).add_to(map_fp_percentage)\n",
    "\n",
    "\n",
    "# Add a legend\n",
    "template = \"\"\"\n",
    "{% macro html(this, kwargs) %}\n",
    "<div style=\"position: fixed;\n",
    "     bottom: 50px; left: 50px; width: 130px; height: 100px;\n",
    "     border:2px solid grey; z-index:9999; font-size:12px;\n",
    "     background-color: white;\n",
    "     opacity: 0.9;\n",
    "     \">\n",
    "     <p style=\"margin-left: 5px;\">Percentage of FP per state - validation</p>\n",
    "     <ul style=\"list-style-type:none; padding-left: 5px;\">\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#008f86\"></i> >= 15%</li>\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#69dab3\"></i> < 15%</li>\n",
    "     </ul>\n",
    "</div>\n",
    "{% endmacro %}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "macro = MacroElement()\n",
    "macro._template = Template(template)\n",
    "\n",
    "map_fp_percentage.get_root().add_child(macro)\n",
    "\n",
    "# Display the map\n",
    "map_fp_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2e372ef-3e07-4125-b0cf-385441b79d86",
     "showTitle": true,
     "title": "FP - test"
    }
   },
   "outputs": [],
   "source": [
    "# map centered on the US\n",
    "map_fp_percentage = folium.Map(location=[39.50, -98.35], zoom_start=4)\n",
    "\n",
    "#chose 75th percentile\n",
    "def get_color(percentage):\n",
    "    \"\"\"\n",
    "    Produces color based on range of % FP\n",
    "    \"\"\"\n",
    "    if percentage >= 15:\n",
    "        return \"#008f86\"\n",
    "    else:\n",
    "        return \"#69dab3\"\n",
    "\n",
    "\n",
    "for index, row in geo_fp_percentage_test.iterrows():\n",
    "    state = row[\"state\"]\n",
    "    percentage_FP = row[\"percentage_FP\"]\n",
    "    color = get_color(percentage_FP)\n",
    "\n",
    "    # Create a GeoJson overlay for each state if the geometry is not None\n",
    "    if row[\"geometry\"]:\n",
    "        folium.GeoJson(\n",
    "            row[\"geometry\"],\n",
    "            style_function=lambda x, color=color: {\n",
    "                \"fillColor\": color,\n",
    "                \"color\": \"black\",\n",
    "                \"weight\": 2,\n",
    "                \"fillOpacity\": 0.8,\n",
    "            },\n",
    "        ).add_to(map_fp_percentage)\n",
    "\n",
    "\n",
    "# Add a legend\n",
    "template = \"\"\"\n",
    "{% macro html(this, kwargs) %}\n",
    "<div style=\"position: fixed;\n",
    "     bottom: 50px; left: 50px; width: 130px; height: 100px;\n",
    "     border:2px solid grey; z-index:9999; font-size:12px;\n",
    "     background-color: white;\n",
    "     opacity: 0.9;\n",
    "     \">\n",
    "     <p style=\"margin-left: 5px;\">Percentage of FP per state - test</p>\n",
    "     <ul style=\"list-style-type:none; padding-left: 5px;\">\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#008f86\"></i> >= 15%</li>\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#69dab3\"></i> < 15%</li>\n",
    "     </ul>\n",
    "</div>\n",
    "{% endmacro %}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "macro = MacroElement()\n",
    "macro._template = Template(template)\n",
    "\n",
    "map_fp_percentage.get_root().add_child(macro)\n",
    "\n",
    "# Display the map\n",
    "map_fp_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3001e227-4431-4bfb-86fe-2628b4a0be57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn_percentage_pandas_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f5b61d-8b49-4736-8951-3d745ae7418e",
     "showTitle": true,
     "title": "FN - test"
    }
   },
   "outputs": [],
   "source": [
    "# map centered on the US\n",
    "map_fn_percentage = folium.Map(location=[39.50, -98.35], zoom_start=4)\n",
    "\n",
    "#chose 75%ile\n",
    "def get_color(percentage):\n",
    "    \"\"\"\n",
    "    Produces color based on range of % FN\n",
    "    \"\"\"\n",
    "    if percentage >= 15:\n",
    "        return \"#e92658\"\n",
    "    else:\n",
    "        return \"#ef9816\"\n",
    "\n",
    "\n",
    "for index, row in geo_fn_percentage_test.iterrows():\n",
    "    state = row[\"state\"]\n",
    "    percentage_FN = row[\"percentage_FN\"]\n",
    "    color = get_color(percentage_FN)\n",
    "\n",
    "    # Create a GeoJson overlay for each state if the geometry is not None\n",
    "    if row[\"geometry\"]:\n",
    "        folium.GeoJson(\n",
    "            row[\"geometry\"],\n",
    "            style_function=lambda x, color=color: {\n",
    "                \"fillColor\": color,\n",
    "                \"color\": \"black\",\n",
    "                \"weight\": 2,\n",
    "                \"fillOpacity\": 0.8,\n",
    "            },\n",
    "        ).add_to(map_fn_percentage)\n",
    "\n",
    "\n",
    "# Add a legend\n",
    "template = \"\"\"\n",
    "{% macro html(this, kwargs) %}\n",
    "<div style=\"position: fixed;\n",
    "     bottom: 50px; left: 50px; width: 130px; height: 100px;\n",
    "     border:2px solid grey; z-index:9999; font-size:12px;\n",
    "     background-color: white;\n",
    "     opacity: 0.9;\n",
    "     \">\n",
    "     <p style=\"margin-left: 5px;\">Percentage of FN per state - test</p>\n",
    "     <ul style=\"list-style-type:none; padding-left: 5px;\">\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#e92658\"></i> >= 15%</li>\n",
    "         <li><i class=\"fa fa-square fa-lg\" style=\"color:#ef9816\"></i> < 15%</li>\n",
    "     </ul>\n",
    "</div>\n",
    "{% endmacro %}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "macro = MacroElement()\n",
    "macro._template = Template(template)\n",
    "\n",
    "map_fn_percentage.get_root().add_child(macro)\n",
    "\n",
    "# Display the map\n",
    "map_fn_percentage"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2340268507062808,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "gap_analysis_ensemble",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
